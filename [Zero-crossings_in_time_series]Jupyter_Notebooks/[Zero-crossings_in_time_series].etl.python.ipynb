{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[Zero-crossings_in_time_series].etl.python.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMSRFdyqIRGQbNdzz8Ilez+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8IKpn2d34qoY"},"source":["# Efficient determination of zero-crossings in noisy real-life time series\r\n","## Advanced Data Science Capstone Project\r\n","### Extract, Transform, Load.\r\n","In this notebook, the data is provided from an internal or external dataset and transformed into the required format. The presented functions are called during the simulation every time, when a new data should be passed into the models. "]},{"cell_type":"code","metadata":{"id":"wEfWl2dv8TVK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614889303033,"user_tz":-60,"elapsed":49170,"user":{"displayName":"Marat Mukhametzhanov","photoUrl":"","userId":"00296603522146618027"}},"outputId":"3dd56e27-b95f-4a18-eeb0-d1033c542c67"},"source":["#Here, the path to the file [Zero_crossings_in_time_series]_import_libraries_python.ipynb should be indicated.\r\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n","\u001b[K     |████████████████████████████████| 212.3MB 70kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 17.6MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=d0b5491c5545384dffd96fb4dd7a51be00fbd517aba77fe551f0baaa1e8b1225\n","  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Auad6bKv6bse"},"source":["First, $N$ time steps $t_1,~t_2,...,~t_N$ are generated starting from the initial time $t_0$. The simplest way is to generate these values using a static or dynamic stepsize $h$ or $\\Delta t$: $t_k = t_{k-1} + h$, but sometimes in real-life applications we cannot choose, when to estimate the system's state: in this case, the time observations $t_k$ are generated out of the simulated system. For example, the choice is based on the concrete sensors and/or resources required for getting and loading a new data: e.g., sending the data from a starship requires some resources, so it cannot be performed each second. \r\n","At this moment, an external dataset is not connected just for simplicity, but it can be done very easily in the following function."]},{"cell_type":"code","metadata":{"id":"YDOP0otO3cdj","executionInfo":{"status":"ok","timestamp":1614889195792,"user_tz":-60,"elapsed":640,"user":{"displayName":"Marat Mukhametzhanov","photoUrl":"","userId":"00296603522146618027"}}},"source":["def provide_new_time_steps(t0,N=1,h=None):\r\n","  if h==None:\r\n","    #External dataset should be connected here\r\n","    #Data is read from the external dataset\r\n","    print('Database is not found')\r\n","  else:\r\n","    return np.arange(t0+h,t0+h+N*h-h/100,h)\r\n","#############################################\r\n"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tLs0T6kg6eo1"},"source":["Second, new data is received from an external dataset or generated internally. Here, the `time_steps` is the array of the time observations $t_1, t_2, ..., t_N$, where we want to obtain the values of the objective function from an external dataset or to generate them internally using the function $f(\\cdot)$. A random noise with the standard deviation $\\sigma$ is added only during the generation of the values internally. Otherwise, the noise can be already in the data (e.g., the noise from the sensors). The `model_context` argument indicates in which format do we keep the data: if it is equal to 0 or to 2, then the standard numpy arrays are used. If `model_context=1`, then the Spark dataframe is used. \r\n","\r\n","Finally, only numerical data is returned: if, e.g., the data was not read correctly and has been returned as a NaN (\"Not a number\"), then it is not stored. I.e., at this step, we also check the correctness of the format of the data."]},{"cell_type":"code","metadata":{"id":"3TT4Xw0E6e-Y","executionInfo":{"status":"ok","timestamp":1614889196922,"user_tz":-60,"elapsed":697,"user":{"displayName":"Marat Mukhametzhanov","photoUrl":"","userId":"00296603522146618027"}}},"source":["def provide_new_data(time_steps,f=None,sigma=0,model_context=0):\r\n","  t = []\r\n","  y = []\r\n","  for i in range(time_steps.shape[0]):\r\n","    if f==None:\r\n","      #External dataset should be connected here\r\n","      #Data is read from the external dataset\r\n","      print('Database is not found')\r\n","    try:\r\n","      y_temp = f(time_steps[i])\r\n","      y_new = y_temp+sigma*random.gauss(0,1)\r\n","    except:\r\n","      print(\"Error: database is not connected.\")\r\n","      raise\r\n","    if np.logical_not(np.isnan(y_new)).all:\r\n","      if model_context==1:\r\n","        t.append(Vectors.dense(time_steps[i]))\r\n","      else:\r\n","        t.append(time_steps[i])\r\n","      y.append(float(y_new))\r\n","  if model_context==1:\r\n","    return spark.createDataFrame(sc.parallelize(zip(t,y)),[\"t\",\"x\"]),None\r\n","  else:\r\n","    return np.array(t),np.array(y)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bIANygwj8urp"},"source":["Just an example of applying the above mentioned steps."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"voYoQ_s_8zsD","executionInfo":{"status":"ok","timestamp":1614889320486,"user_tz":-60,"elapsed":8357,"user":{"displayName":"Marat Mukhametzhanov","photoUrl":"","userId":"00296603522146618027"}},"outputId":"7b0bbc95-0e4d-48bd-b3d6-31bae8be64e3"},"source":["print(\"Just an example of ETL steps.\")\r\n","f = lambda x: x**2-4.0*x+4\r\n","t0 = 0\r\n","t = provide_new_time_steps(t0,N=10,h=0.1)\r\n","t = np.append(t0,t)\r\n","print(t)\r\n","t, y_arrays = provide_new_data(t,f=f,sigma=0.01,model_context=0)\r\n","print(y_arrays)\r\n","y_spark,temp = provide_new_data(t,f=f,sigma=0.01,model_context=1)\r\n","y_spark.show(20)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Just an example of ETL steps.\n","[0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n","[4.00708449 3.61691693 3.25130688 2.88846642 2.55638148 2.25977529\n"," 1.96120969 1.68663897 1.42891945 1.21765965 0.99943552]\n","+--------------------+------------------+\n","|                   t|                 x|\n","+--------------------+------------------+\n","|               [0.0]| 4.008201203643661|\n","|               [0.1]|3.5905099317204656|\n","|               [0.2]|3.2399810138404868|\n","|[0.30000000000000...| 2.888485040952631|\n","|               [0.4]| 2.550800429047671|\n","|               [0.5]| 2.248550474394978|\n","|               [0.6]| 1.968275687250734|\n","|[0.7000000000000001]|1.6912594765938327|\n","|               [0.8]|1.4457836903118393|\n","|               [0.9]|   1.2112731810473|\n","|               [1.0]|0.9932533850743942|\n","+--------------------+------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CIciGDcQ9ODE"},"source":[""],"execution_count":null,"outputs":[]}]}